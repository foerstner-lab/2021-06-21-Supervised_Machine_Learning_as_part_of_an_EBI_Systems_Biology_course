{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "%pip install biopython\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30599a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import multiprocessing\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d136d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => Utility functions\n",
    "\n",
    "# Function to read text files of sequences\n",
    "def read_seq_file(in_path):\n",
    "    with open(os.path.abspath(os.path.expanduser(in_path)), \"r\") as f:\n",
    "        sequences = f.read().splitlines()\n",
    "    return sequences\n",
    "\n",
    "\n",
    "# Function to vectorize each sequence, produces 1d flattened vectors\n",
    "def vectorize_sequence(seq):\n",
    "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    dum_df = pd.get_dummies(list(seq), dtype=int)\n",
    "    for base in bases:\n",
    "        if base not in dum_df.columns:\n",
    "            dum_df[base] = 0\n",
    "    dum_df = dum_df.reindex(bases, axis=1)\n",
    "    return dum_df.to_numpy().flatten()\n",
    "\n",
    "\n",
    "# Function to generate an array of all vectorized sequences\n",
    "def generate_sequences_vector_arr(sequences, threads):\n",
    "    pool = multiprocessing.Pool(threads)\n",
    "    return np.array(pool.map(vectorize_sequence, sequences), dtype=np.int32)\n",
    "\n",
    "\n",
    "# Function to convert classification prediction into genomic intervals\n",
    "def generate_genomic_locations(classes, proba, window_size):\n",
    "    loc_pairs = []\n",
    "    classes_len = classes.shape[0]\n",
    "    counter = 0\n",
    "    while counter < classes_len:\n",
    "        pred_class = classes[counter]\n",
    "        if pred_class != 0:\n",
    "            loc_pairs.append([counter + 1, counter + window_size, \"+\" if pred_class == 1 else \"-\"])\n",
    "            loc_pairs[-1].extend(proba[counter].tolist())\n",
    "        counter += 1\n",
    "    return loc_pairs\n",
    "\n",
    "\n",
    "# Function to convert locations into GFF format\n",
    "def generate_gff_df(locations, seqid, score_filter=0.001):\n",
    "    column_names = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attribute\"]\n",
    "    strand_func = lambda x: \"F\" if x == \"+\" else \"R\"\n",
    "    # small function to generate attributes\n",
    "    attr_func = lambda row: \\\n",
    "        f\"id={row['seqid']}_{strand_func(row['strand'])}_prom_{row.name}\" \\\n",
    "        f\";name={row['seqid']}_{strand_func(row['strand'])}_prom_{row.name}\" \\\n",
    "        f\";true_proba={row['true_proba']}\" \\\n",
    "        f\";true_rc_proba={row['true_rc_proba']}\" \\\n",
    "        f\";false_proba={row['false_proba']}\"\n",
    "\n",
    "    gff_df = pd.DataFrame(locations, columns=[\"start\", \"end\", \"strand\", \"true_proba\", \"true_rc_proba\", \"false_proba\"])\n",
    "    f_gff_df = gff_df[(gff_df[\"strand\"] == \"+\") & (gff_df[\"true_proba\"] <= score_filter)].copy()\n",
    "    r_gff_df = gff_df[(gff_df[\"strand\"] == \"-\") & (gff_df[\"true_rc_proba\"] <= score_filter)].copy()\n",
    "    gff_df = f_gff_df.append(r_gff_df, ignore_index=True)\n",
    "    gff_df[\"seqid\"] = seqid\n",
    "    gff_df[\"source\"] = \"ML_promoters_predictor\"\n",
    "    gff_df[\"type\"] = \"predicted_promoter\"\n",
    "    gff_df[\"score\"] = \".\"\n",
    "    gff_df[\"phase\"] = \".\"\n",
    "\n",
    "    for i in gff_df.index:\n",
    "        gff_df.at[i, \"attribute\"] = attr_func(gff_df.loc[i])\n",
    "    gff_df.drop([\"true_proba\", \"false_proba\"], inplace=True, axis=1)\n",
    "    gff_df = gff_df.reindex(columns=column_names)\n",
    "    return gff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1799d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "genome_file = \"./GCF_000005845.2_ASM584v2_genomic.fa\"\n",
    "true_bs_file = \"./sigE_binding_sites.txt\"\n",
    "false_bs_file = \"./dummy_seq.txt\"\n",
    "save_dir = \"./\"\n",
    "iterations = 500\n",
    "window_size = 29\n",
    "threads = 40\n",
    "score_filter = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e681df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input files\n",
    "save_dir = os.path.abspath(save_dir)\n",
    "genome_file_parsed = SeqIO.parse(os.path.abspath(genome_file), \"fasta\")\n",
    "true_sequences = read_seq_file(true_bs_file)\n",
    "true_rc_sequences = [str(Seq(s).reverse_complement()) for s in true_sequences]\n",
    "false_sequences = read_seq_file(false_bs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239a06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training data sets in a parallel mode and make dataframes of it (takes time!)\n",
    "true_dataset_arr = generate_sequences_vector_arr(true_sequences, threads)\n",
    "true_rc_dataset_arr = generate_sequences_vector_arr(true_rc_sequences, threads)\n",
    "false_dataset_arr = generate_sequences_vector_arr(false_sequences, threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b47989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training datasets\n",
    "full_arr = np.concatenate([true_dataset_arr, true_rc_dataset_arr, false_dataset_arr], axis=0)\n",
    "labels = ([1] * true_dataset_arr.shape[0]) + ([-1] * true_rc_dataset_arr.shape[0]) + ([0] * false_dataset_arr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b307a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f68c6d206d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = CatBoostClassifier(iterations=iterations)\n",
    "model.fit(full_arr, labels, silent=True)\n",
    "#model.save_model(os.path.abspath(f\"{save_dir}/{os.path.basename(true_bs_file)}2.cbm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4eff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Processing: NC_000913.3\n",
      "Saving GFF\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "save_df = pd.DataFrame()\n",
    "for seq_rec in genome_file_parsed:\n",
    "    print(f\"==> Processing: {seq_rec.id}\")\n",
    "    # Vectorize the genomic sequence\n",
    "    chrom_vector = vectorize_sequence(str(seq_rec.seq))\n",
    "    # Convert vectorized genome to array of sliding windows\n",
    "    dataset_arr = sliding_window_view(chrom_vector, window_size * 4)[::4]\n",
    "    del chrom_vector\n",
    "    # Classify\n",
    "    predict = model.predict(dataset_arr, thread_count=threads)\n",
    "    # Get classification probabilities\n",
    "    proba = model.predict_proba(dataset_arr, thread_count=threads)\n",
    "    # Make genomic coordenates from the classification result\n",
    "    locations = generate_genomic_locations(predict, proba, window_size)\n",
    "    # Convert to GFF format\n",
    "    gff = generate_gff_df(locations, seq_rec.id, score_filter)\n",
    "    save_df = save_df.append(gff, ignore_index=True)\n",
    "save_df.sort_values(by=[\"seqid\", \"start\", \"end\"], inplace=True)\n",
    "print(\"Saving GFF\")\n",
    "save_df.to_csv(os.path.abspath(f\"{save_dir}/predicted_promoters_catboost.gff\"), sep=\"\\t\", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
