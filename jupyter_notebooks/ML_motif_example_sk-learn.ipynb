{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "%pip install biopython\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff445fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import numpy as np\n",
    "from Bio import SeqIO, motifs, AlignIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0507227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => Utility functions\n",
    "# Function to read text files of sequences\n",
    "def read_seq_file(in_path):\n",
    "    with open(os.path.abspath(os.path.expanduser(in_path)), \"r\") as f:\n",
    "        sequences = f.read().splitlines()\n",
    "    return sequences\n",
    "\n",
    "# Function to generate list of false sequences\n",
    "def generate_false_sequences(true_seq):\n",
    "    false_seq = []\n",
    "    for seq in true_seq:\n",
    "        x = list(seq)\n",
    "        random.shuffle(x)\n",
    "        false_seq.append(''.join(x))\n",
    "    return false_seq\n",
    "\n",
    "# Function to convert classification prediction into genomic intervals\n",
    "def generate_genomic_locations(classes, proba, window_size):\n",
    "    loc_pairs = []\n",
    "    classes_len = classes.shape[0]\n",
    "    counter = 0\n",
    "    while counter < classes_len: \n",
    "        if classes[counter] == 1:\n",
    "            loc_pairs.append([counter + 1, counter + window_size])\n",
    "            loc_pairs[-1].extend(proba[counter].tolist())\n",
    "        counter += 1\n",
    "    return loc_pairs\n",
    "\n",
    "\n",
    "# Function to convert locations into GFF format\n",
    "def generate_gff_df(locations, seqid, strand, score_filter=0.001):\n",
    "    column_names = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attribute\"]\n",
    "    strand_letter = \"F\" if strand == \"+\" else \"R\"\n",
    "    # small function to generate attributes\n",
    "    attr_func = lambda row: \\\n",
    "        f\"id={row['seqid']}_{strand_letter}_prom_{row.name}\" \\\n",
    "        f\";name={row['seqid']}_{strand_letter}_prom_{row.name}\" \\\n",
    "        f\";true_proba={row['true_proba']};false_proba={row['false_proba']}\"\n",
    "\n",
    "    gff_df = pd.DataFrame(locations, columns=[\"start\", \"end\", \"true_proba\", \"false_proba\"])\n",
    "    gff_df = gff_df[gff_df[\"true_proba\"] <= score_filter].copy()\n",
    "    gff_df[\"seqid\"] = seqid\n",
    "    gff_df[\"source\"] = \"motif_predictor\"\n",
    "    gff_df[\"type\"] = \"motif\"\n",
    "    gff_df[\"score\"] = \".\"\n",
    "    gff_df[\"strand\"] = strand\n",
    "    gff_df[\"phase\"] = \".\"\n",
    "\n",
    "    for i in gff_df.index:\n",
    "        gff_df.at[i, \"attribute\"] = attr_func(gff_df.loc[i])\n",
    "    gff_df.drop([\"true_proba\", \"false_proba\"], inplace=True, axis=1)\n",
    "    gff_df = gff_df.reindex(columns=column_names)\n",
    "    return gff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "promoters_seq_url = \"http://regulondb.ccg.unam.mx/menu/download/datasets/files/PromoterSigma24Set.txt\"\n",
    "genome_file = \"./GCF_000005845.2_ASM584v2_genomic.fa\"\n",
    "#true_bs_file = \"./sigE_binding_sites.txt\"\n",
    "save_dir = \"./\"\n",
    "iterations = 500\n",
    "threads = 40\n",
    "score_filter = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128088c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load promoter sequences and analyze them\n",
    "prom_col = [\"id\", \"name\", \"strand\", \"tss\", \"sigma_name\", \"sequence\", \"evidence\", \"confidence\"]\n",
    "promotors_df = pd.read_csv(promoters_seq_url, comment=\"#\", sep=\"\\t\", names=prom_col)\n",
    "promotors_df.dropna(subset = [\"sequence\"], inplace=True)\n",
    "promotors_df = promotors_df[promotors_df[\"confidence\"].isin([\"Strong\", \"Confirmed\"])]\n",
    "promoters = [prom[: 60].upper() for prom in promotors_df[\"sequence\"]]\n",
    "window_size = len(promoters[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d33b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input files\n",
    "save_dir = os.path.abspath(save_dir)\n",
    "genome_file_parsed = SeqIO.parse(os.path.abspath(genome_file), \"fasta\")\n",
    "#true_sequences = read_seq_file(true_bs_file)\n",
    "true_sequences = promoters\n",
    "false_sequences = generate_false_sequences(true_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize each sequence, produces 1d flattened vectors\n",
    "vector_func = lambda seq: label_binarize(list(seq), classes=list(\"ATCG\")).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dfd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training data sets in a parallel mode and make dataframes of it\n",
    "\n",
    "true_dataset_arr = np.array(list(map(vector_func, true_sequences)), dtype=np.int32)\n",
    "false_dataset_arr = np.array(list(map(vector_func, false_sequences)), dtype=np.int32)\n",
    "# Concatenate training datasets\n",
    "full_arr = np.concatenate([true_dataset_arr, false_dataset_arr], axis=0)\n",
    "labels = ([1] * true_dataset_arr.shape[0]) + ([0] * false_dataset_arr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba79fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for prediction\n",
    "f_data_to_predict = {}\n",
    "r_data_to_predict = {}\n",
    "for seq_rec in genome_file_parsed:\n",
    "    print(f\"==> Preparing: {seq_rec.id}\")\n",
    "    # Vectorize the genomic sequence forward and reverse\n",
    "    f_chrom_vector = vector_func(str(seq_rec.seq))\n",
    "    r_chrom_vector = vector_func(str(seq_rec.reverse_complement().seq))\n",
    "    # Convert vectorized genome to array of sliding windows\n",
    "    f_data_to_predict[seq_rec.id] = sliding_window_view(f_chrom_vector, window_size * 4)[::4]\n",
    "    r_data_to_predict[seq_rec.id] = sliding_window_view(r_chrom_vector, window_size * 4)[::4]\n",
    "    del f_chrom_vector, r_chrom_vector # free some memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"RandomForest\": RandomForestClassifier(n_jobs=threads),\n",
    "          \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "          \"AdaBoost\": AdaBoostClassifier(),\n",
    "          \"MultiLayerPerceptron\": MLPClassifier(max_iter=iterations)}\n",
    "thresholds = {\"RandomForest\": 0.1,\n",
    "              \"GradientBoosting\": 0.05,\n",
    "              \"AdaBoost\": 0.43,\n",
    "              \"MultiLayerPerceptron\": 0.005}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    t = time.time()\n",
    "    # Train\n",
    "    print(f\"==> Training {model_name} model\")\n",
    "    model.fit(full_arr, labels)\n",
    "    save_df = pd.DataFrame()\n",
    "    for seqid in f_data_to_predict.keys():\n",
    "        print(f\"===> Predicting for: {seqid} using {model_name} model\")        \n",
    "        # Get classification probabilities\n",
    "        f_proba = model.predict_proba(f_data_to_predict[seqid])\n",
    "        r_proba = model.predict_proba(r_data_to_predict[seqid])\n",
    "        # Get classes from propabilities\n",
    "        f_predict_classes = np.array([model.classes_[i] for i in np.argmax(f_proba, axis=1)])\n",
    "        r_predict_classes = np.array([model.classes_[i] for i in np.argmax(r_proba, axis=1)])\n",
    "        # Make genomic coordenates from the classification result\n",
    "        f_locations = generate_genomic_locations(f_predict_classes, f_proba, window_size)\n",
    "         # Filp the array up down for reverse strand\n",
    "        r_locations = generate_genomic_locations(np.flipud(r_predict_classes), np.flipud(r_proba), window_size)\n",
    "        # Convert to GFF format\n",
    "        f_gff = generate_gff_df(f_locations, seq_rec.id, \"+\", thresholds[model_name])\n",
    "        r_gff = generate_gff_df(r_locations, seq_rec.id, \"-\", thresholds[model_name])\n",
    "        save_df = save_df.append(f_gff, ignore_index=True)\n",
    "        save_df = save_df.append(r_gff, ignore_index=True)\n",
    "    \n",
    "    print(f\"Time elapsed for {model_name} model: {round((time.time() - t) / 60, 2)} minutes\")\n",
    "    \n",
    "    print(f\"Predicted motifs count: {save_df.shape[0]} at threshold {thresholds[model_name]}\")\n",
    "    save_df.sort_values(by=[\"seqid\", \"start\", \"end\"], inplace=True)\n",
    "    print(\"Saving GFF\")\n",
    "    save_df.to_csv(os.path.abspath(f\"{save_dir}/predicted_promoters_sk_{model_name}.gff\"),\n",
    "                   sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb958d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e810f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a469121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ae8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc70c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c29b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377e163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
