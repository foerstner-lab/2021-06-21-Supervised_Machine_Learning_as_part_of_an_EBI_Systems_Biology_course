{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "%pip install biopython\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c45f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from astropy.stats import bayesian_blocks\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbcf9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# => Utility functions\n",
    "# Function to read text files of sequences\n",
    "def read_seq_file(in_path):\n",
    "    with open(os.path.abspath(os.path.expanduser(in_path)), \"r\") as f:\n",
    "        sequences = f.read().splitlines()\n",
    "    return sequences\n",
    "\n",
    "# Function to generate list of false sequences\n",
    "def generate_false_sequences(true_seq):\n",
    "    false_seq = []\n",
    "    for seq in true_seq:\n",
    "        x = list(seq)\n",
    "        random.shuffle(x)\n",
    "        false_seq.append(''.join(x))\n",
    "    return false_seq\n",
    "\n",
    "# Function to vectorize each sequence, produces 1d flattened vectors\n",
    "def one_hot_encoder(seq):\n",
    "    integer_encoded = LabelEncoder().fit(np.array([\"A\", \"C\", \"G\", \"T\"])).transform(list(seq)).reshape(len(list(seq)), 1)\n",
    "    return OneHotEncoder(sparse=False, dtype=int, categories=[range(4)]).fit_transform(integer_encoded).flatten()\n",
    "\n",
    "\n",
    "# Function to convert classification prediction into genomic intervals\n",
    "def generate_genomic_locations(classes, proba, window_size):\n",
    "    loc_pairs = []\n",
    "    classes_len = classes.shape[0]\n",
    "    counter = 0\n",
    "    while counter < classes_len:\n",
    "        pred_class = classes[counter]\n",
    "        if pred_class != 0:\n",
    "            loc_pairs.append([counter + 1, counter + window_size, \"+\" if pred_class == 1 else \"-\"])\n",
    "            loc_pairs[-1].extend(proba[counter].tolist())\n",
    "        counter += 1\n",
    "    return loc_pairs\n",
    "\n",
    "\n",
    "# Function to convert locations into GFF format\n",
    "def generate_gff_df(locations, seqid, score_filter=0.001):\n",
    "    column_names = [\"seqid\", \"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attribute\"]\n",
    "    strand_func = lambda x: \"F\" if x == \"+\" else \"R\"\n",
    "    # small function to generate attributes\n",
    "    attr_func = lambda row: \\\n",
    "        f\"id={row['seqid']}_{strand_func(row['strand'])}_prom_{row.name}\" \\\n",
    "        f\";name={row['seqid']}_{strand_func(row['strand'])}_prom_{row.name}\" \\\n",
    "        f\";true_proba={row['true_proba']}\" \\\n",
    "        f\";true_rc_proba={row['true_rc_proba']}\" \\\n",
    "        f\";false_proba={row['false_proba']}\"\n",
    "\n",
    "    gff_df = pd.DataFrame(locations, columns=[\"start\", \"end\", \"strand\", \"true_proba\", \"true_rc_proba\", \"false_proba\"])\n",
    "    f_gff_df = gff_df[(gff_df[\"strand\"] == \"+\") & (gff_df[\"true_proba\"] <= score_filter)].copy()\n",
    "    r_gff_df = gff_df[(gff_df[\"strand\"] == \"-\") & (gff_df[\"true_rc_proba\"] <= score_filter)].copy()\n",
    "    gff_df = f_gff_df.append(r_gff_df, ignore_index=True)\n",
    "    gff_df[\"seqid\"] = seqid\n",
    "    gff_df[\"source\"] = \"ML_promoters_predictor\"\n",
    "    gff_df[\"type\"] = \"predicted_promoter\"\n",
    "    gff_df[\"score\"] = \".\"\n",
    "    gff_df[\"phase\"] = \".\"\n",
    "\n",
    "    for i in gff_df.index:\n",
    "        gff_df.at[i, \"attribute\"] = attr_func(gff_df.loc[i])\n",
    "    gff_df.drop([\"true_proba\", \"false_proba\"], inplace=True, axis=1)\n",
    "    gff_df = gff_df.reindex(columns=column_names)\n",
    "    return gff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587a77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "genome_file = \"./GCF_000005845.2_ASM584v2_genomic.fa\"\n",
    "true_bs_file = \"./sigE_binding_sites.txt\"\n",
    "false_bs_file = \"./dummy_seq.txt\"\n",
    "save_dir = \"./\"\n",
    "iterations = 500\n",
    "window_size = 29\n",
    "threads = 40\n",
    "score_filter = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e51f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input files\n",
    "save_dir = os.path.abspath(save_dir)\n",
    "genome_file_parsed = SeqIO.parse(os.path.abspath(genome_file), \"fasta\")\n",
    "true_sequences = read_seq_file(true_bs_file)\n",
    "true_rc_sequences = [str(Seq(s).reverse_complement()) for s in true_sequences]\n",
    "false_sequences = generate_false_sequences(true_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff6d9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training data sets in a parallel mode and make dataframes of it\n",
    "\n",
    "true_dataset_arr = np.array(list(map(one_hot_encoder, true_sequences)), dtype=np.int32)\n",
    "true_rc_dataset_arr = np.array(list(map(one_hot_encoder, true_rc_sequences)), dtype=np.int32)\n",
    "false_dataset_arr = np.array(list(map(one_hot_encoder, false_sequences)), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a632bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training datasets\n",
    "full_arr = np.concatenate([true_dataset_arr, true_rc_dataset_arr, false_dataset_arr], axis=0)\n",
    "labels = ([1] * true_dataset_arr.shape[0]) + ([-1] * true_rc_dataset_arr.shape[0]) + ([0] * false_dataset_arr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00d503af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing: NC_000913.3\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for prediction\n",
    "data_to_predict = {}\n",
    "for seq_rec in genome_file_parsed:\n",
    "    print(f\"==> Preparing: {seq_rec.id}\")\n",
    "    # Vectorize the genomic sequence\n",
    "    chrom_vector = one_hot_encoder(str(seq_rec.seq))\n",
    "    # Convert vectorized genome to array of sliding windows\n",
    "    data_to_predict[seq_rec.id] = sliding_window_view(chrom_vector, window_size * 4)[::4]\n",
    "    del chrom_vector # free some memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39303578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training RandomForest model\n",
      "===> Predicting for: NC_000913.3 using RandomForest model\n",
      "Time elapsed for RandomForest model: 0.59 minutes\n",
      "Predicted motifs count: 72071\n",
      "Saving GFF\n"
     ]
    }
   ],
   "source": [
    "models = {\"RandomForest\": RandomForestClassifier(n_jobs=threads),\n",
    "          \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "          \"AdaBoost\": AdaBoostClassifier(),\n",
    "          \"MultiLayerPerceptron\": MLPClassifier(max_iter=iterations),\n",
    "          \"GaussianNaiveBayes\": GaussianNB(),\n",
    "          \"DecisionTree\": DecisionTreeClassifier(),\n",
    "          \"KNearestNeighbors\": KNeighborsClassifier(n_jobs=threads)}\n",
    "thresholds = {\"RandomForest\": 0.05,\n",
    "          \"GradientBoosting\": 0,\n",
    "          \"AdaBoost\": 0,\n",
    "          \"MultiLayerPerceptron\": 0,\n",
    "          \"GaussianNaiveBayes\": 0,\n",
    "          \"DecisionTree\": 0,\n",
    "          \"KNearestNeighbors\": 0}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    t = time.time()\n",
    "    # Train\n",
    "    print(f\"==> Training {model_name} model\")\n",
    "    model.fit(full_arr, labels)\n",
    "    save_df = pd.DataFrame()\n",
    "    probas = np.empty((0, 3), float)\n",
    "    for seqid in data_to_predict.keys():\n",
    "        print(f\"===> Predicting for: {seqid} using {model_name} model\")\n",
    "        # Classify\n",
    "        # predict = model.predict(data_to_predict[seqid])\n",
    "        \n",
    "        # Get classification probabilities\n",
    "        proba = model.predict_proba(data_to_predict[seqid])\n",
    "        probas = np.vstack((probas, proba))\n",
    "        # Get classes from propabilities\n",
    "        predict_classes = np.array([model.classes_[i] for i in np.argmax(proba, axis=1)])\n",
    "        # Make genomic coordenates from the classification result\n",
    "        locations = generate_genomic_locations(predict_classes, proba, window_size)\n",
    "        # Convert to GFF format\n",
    "        gff = generate_gff_df(locations, seq_rec.id, thresholds[model_name])\n",
    "        save_df = save_df.append(gff, ignore_index=True)\n",
    "    print(f\"Time elapsed for {model_name} model: {round((time.time() - t) / 60, 2)} minutes\")\n",
    "    \n",
    "    print(f\"Predicted motifs count: {save_df.shape[0]}\")\n",
    "    \n",
    "    save_df.sort_values(by=[\"seqid\", \"start\", \"end\"], inplace=True)\n",
    "    print(\"Saving GFF\")\n",
    "    save_df.to_csv(os.path.abspath(f\"{save_dir}/predicted_promoters_sk_{model_name}.gff\"),\n",
    "                   sep=\"\\t\", header=False, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791cb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ee15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56cb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432875a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4db36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952f577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e66e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
